# Scenario 1: Invoke Llama 3.1 without a chat template

This scenario demonstrates how to invoke the Llama 3.1 model using the native Bedrock API without a chat template.

## What you'll learn:
- Basic structure of a request to the Bedrock API
- How to process the response from the model
- Direct interaction with the Llama 3.1 model

## Key concepts:
- **Native API**: Using the raw Bedrock API without additional formatting
- **Request structure**: Understanding the JSON format required by Bedrock
- **Response handling**: Extracting and displaying the model's output 